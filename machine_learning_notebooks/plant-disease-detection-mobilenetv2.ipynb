{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import OS module\nimport os\n\n# Imports\nimport numpy as np\nimport pandas as pd\n\n# Visualization\nimport matplotlib.pyplot as plt\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import callbacks, layers, Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Notebook magic\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-07T18:13:06.491Z","iopub.execute_input":"2022-01-07T18:13:06.491374Z","iopub.status.idle":"2022-01-07T18:13:11.155781Z","shell.execute_reply.started":"2022-01-07T18:13:06.491275Z","shell.execute_reply":"2022-01-07T18:13:11.15493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2022-01-07T18:13:11.157201Z","iopub.execute_input":"2022-01-07T18:13:11.157558Z","iopub.status.idle":"2022-01-07T18:13:11.166019Z","shell.execute_reply.started":"2022-01-07T18:13:11.157521Z","shell.execute_reply":"2022-01-07T18:13:11.16518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if GPU available\n!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-01-07T18:13:11.167699Z","iopub.execute_input":"2022-01-07T18:13:11.168367Z","iopub.status.idle":"2022-01-07T18:13:11.880425Z","shell.execute_reply.started":"2022-01-07T18:13:11.168314Z","shell.execute_reply":"2022-01-07T18:13:11.87944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configure variables for Transfer learning\nimage_size = 224\ntarget_size = (image_size, image_size)\ninput_shape = (image_size, image_size, 3)\ngrid_shape = (1, image_size, image_size, 3)\n\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2022-01-07T18:13:11.882064Z","iopub.execute_input":"2022-01-07T18:13:11.882419Z","iopub.status.idle":"2022-01-07T18:13:11.888056Z","shell.execute_reply.started":"2022-01-07T18:13:11.882385Z","shell.execute_reply":"2022-01-07T18:13:11.88717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Image data\n\nWe will be loading all the images in the dataset and apply augmentations to make the model prepared for all kinds of images.\n\nThe Tensorflow and Keras API provides `ImageDataGenerator` for adding the augmentations to be applied to the images, and easily load them from the directory. This automatically keeps track of the class for each image and works seamlessly with the rest of the API.","metadata":{}},{"cell_type":"code","source":"dataset_root = \"/kaggle/input/new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)\"\n\ntrain_dir = os.path.join(dataset_root, \"train\")\ntest_dir = os.path.join(dataset_root, \"valid\")","metadata":{"execution":{"iopub.status.busy":"2022-01-07T18:13:11.889547Z","iopub.execute_input":"2022-01-07T18:13:11.890159Z","iopub.status.idle":"2022-01-07T18:13:11.897194Z","shell.execute_reply.started":"2022-01-07T18:13:11.890121Z","shell.execute_reply":"2022-01-07T18:13:11.896381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define augmentations for train dataset and read the images\ntrain_aug = ImageDataGenerator(\n    # Rescale\n    rescale=1/255.0,\n    # Filling for W/H shift\n    fill_mode=\"nearest\",\n    # Width and Height shift\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    # Random zooms\n    zoom_range=0.2,\n    # Random Shearing aug\n    shear_range=0.2,\n)\n\n# Read data from directory\ntrain_data = train_aug.flow_from_directory(\n    train_dir,\n    target_size=(image_size, image_size),\n    batch_size=batch_size,\n    class_mode=\"categorical\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T18:13:14.012234Z","iopub.execute_input":"2022-01-07T18:13:14.012818Z","iopub.status.idle":"2022-01-07T18:14:06.878021Z","shell.execute_reply.started":"2022-01-07T18:13:14.012691Z","shell.execute_reply":"2022-01-07T18:14:06.877213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the list of categories in training data\ncats = list(train_data.class_indices.keys())\nprint(cats)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T18:14:06.87956Z","iopub.execute_input":"2022-01-07T18:14:06.879915Z","iopub.status.idle":"2022-01-07T18:14:06.886651Z","shell.execute_reply.started":"2022-01-07T18:14:06.879878Z","shell.execute_reply":"2022-01-07T18:14:06.885565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Augmentations for test data\ntest_aug = ImageDataGenerator(\n    # Rescale\n    rescale=1/255.0\n)\n\n# Read data from directory\ntest_data = test_aug.flow_from_directory(\n    test_dir,\n    target_size=(image_size, image_size),\n    batch_size=batch_size,\n    class_mode=\"categorical\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T18:14:06.888667Z","iopub.execute_input":"2022-01-07T18:14:06.889132Z","iopub.status.idle":"2022-01-07T18:14:11.190332Z","shell.execute_reply.started":"2022-01-07T18:14:06.889098Z","shell.execute_reply":"2022-01-07T18:14:11.189384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model building and Training\n\nAs mentioned above, We will be performing Transfer learning with Mobilenet V2 model.\n\nWe get the model with pre-trained weights through API without the Top layer, and Then stack further layers for prediction.\n\nWe used Global Average 2D Pooling for normalization along with dropout, and the final Dense output layer for the prediction.","metadata":{}},{"cell_type":"code","source":"# Load the base model\nmbnet_v2 = keras.applications.MobileNetV2(\n    weights=\"imagenet\",\n    include_top=False,\n    input_shape=input_shape\n)\n\n# Stop from being trainable\nmbnet_v2.trainable = True","metadata":{"execution":{"iopub.status.busy":"2022-01-07T18:14:11.191965Z","iopub.execute_input":"2022-01-07T18:14:11.192238Z","iopub.status.idle":"2022-01-07T18:14:14.316231Z","shell.execute_reply.started":"2022-01-07T18:14:11.192205Z","shell.execute_reply":"2022-01-07T18:14:14.315392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the layers\nimport tensorflow.keras.backend as K\nK.clear_session()\ninputs = keras.Input(shape=input_shape)\n\n# Get the layer\nx = mbnet_v2(inputs, training = False)\n\n# Stack layers further\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(len(cats), activation=\"softmax\")(x)\n\n# Combine the model\nmodel = Model(inputs=inputs, outputs=x)\n\n# Summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T18:17:11.332791Z","iopub.execute_input":"2022-01-07T18:17:11.33323Z","iopub.status.idle":"2022-01-07T18:17:11.668171Z","shell.execute_reply.started":"2022-01-07T18:17:11.333174Z","shell.execute_reply":"2022-01-07T18:17:11.667391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n# Define callbacks to use\nearly_stopping_cb = callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\nreduce_lr = callbacks.ReduceLROnPlateau(monitor = \"val_loss\", patience = 5, factor = 0.3)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T18:17:16.753836Z","iopub.execute_input":"2022-01-07T18:17:16.754156Z","iopub.status.idle":"2022-01-07T18:17:16.771208Z","shell.execute_reply.started":"2022-01-07T18:17:16.754126Z","shell.execute_reply":"2022-01-07T18:17:16.770106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Num epochs\nepochs = 30\n\n# Train model\nhistory = model.fit(\n    train_data,\n    epochs=epochs,\n    steps_per_epoch = 1000, #less than train_data.n // batch_size\n    validation_data = test_data,\n    callbacks=[early_stopping_cb, reduce_lr]\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T18:17:23.169957Z","iopub.execute_input":"2022-01-07T18:17:23.170292Z","iopub.status.idle":"2022-01-07T19:00:23.142616Z","shell.execute_reply.started":"2022-01-07T18:17:23.170259Z","shell.execute_reply":"2022-01-07T19:00:23.138872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T05:14:28.803625Z","iopub.execute_input":"2021-09-30T05:14:28.804307Z","iopub.status.idle":"2021-09-30T05:16:31.43521Z","shell.execute_reply.started":"2021-09-30T05:14:28.804258Z","shell.execute_reply":"2021-09-30T05:16:31.434486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize the model history","metadata":{}},{"cell_type":"code","source":"# Plotting\nhist = history.history\n\n# Plot accuracy and loss\nplt.plot(hist[\"accuracy\"], label=\"accuracy\")\nplt.plot(hist[\"loss\"], label=\"loss\")\n\nif \"val_accuracy\" in hist and \"val_loss\" in hist:\n    plt.plot(hist[\"val_accuracy\"], label=\"val_accuracy\")\n    plt.plot(hist[\"val_loss\"], label=\"val_loss\")\n\n# Add the labels and legend\nplt.ylabel(\"Accuracy / Loss\")\nplt.xlabel(\"Epochs #\")\nplt.legend()\n\n# Finally show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T05:16:31.436535Z","iopub.execute_input":"2021-09-30T05:16:31.437127Z","iopub.status.idle":"2021-09-30T05:16:31.598183Z","shell.execute_reply.started":"2021-09-30T05:16:31.43708Z","shell.execute_reply":"2021-09-30T05:16:31.597199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save and download the model\n\nWe save the model to a file, and link it using IPython to easily get the assets.","metadata":{}},{"cell_type":"code","source":"model.save(\"plant_disease_detection.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-09-30T05:16:31.599677Z","iopub.execute_input":"2021-09-30T05:16:31.600028Z","iopub.status.idle":"2021-09-30T05:16:31.825066Z","shell.execute_reply.started":"2021-09-30T05:16:31.599993Z","shell.execute_reply":"2021-09-30T05:16:31.824176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\nfrom IPython.display import FileLink\n\n# Link the files\nFileLink(\"./plant_disease_detection.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-09-30T05:16:31.826435Z","iopub.execute_input":"2021-09-30T05:16:31.826805Z","iopub.status.idle":"2021-09-30T05:16:31.834033Z","shell.execute_reply.started":"2021-09-30T05:16:31.826768Z","shell.execute_reply":"2021-09-30T05:16:31.832953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dump the categories\nwith open(\"categories.json\", \"w\") as file:\n  json.dump(train_data.class_indices, file)\n\n# Link categories JSON\nFileLink(\"categories.json\")","metadata":{"execution":{"iopub.status.busy":"2021-09-30T05:16:31.835804Z","iopub.execute_input":"2021-09-30T05:16:31.836492Z","iopub.status.idle":"2021-09-30T05:16:31.844925Z","shell.execute_reply.started":"2021-09-30T05:16:31.836438Z","shell.execute_reply":"2021-09-30T05:16:31.843857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}